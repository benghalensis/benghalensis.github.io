---
layout: page
title: Amazon-UW Robotics Manipulation Research 
description: Robot Grasping
img: assets/img/13.jpg
importance: 1
category: work
---
<u>Introduction</u>

Grasp selection is one of the most important problems in robot manipulation where a robot observes an object and needs to decide where to move its gripper (3D position and 3D orientation) in order to pick up the object. Grasp selection is complex since the stability of grasps depends on object and gripper geometry, object mass distribution, and surface frictions. This is particularly hard if the robot is trying to pick an object from the densely packed shelf given by amazon. 

To solve this problem two methods have been tried:
 1. Graspnet
 2. Contact Graspnet
Both of these methods take point cloud data and generate a set of grasps. 

<u>Implementations</u>

 - A grasping node was created that takes in the pointcloud and spits out the grasp poses. This grasping node incorporates the following:
    - Point cloud filtration, 
    - Grasp pose generation using graspnet
    - Grasp pose visualization function
    - Grasp pose filtration
 - A grasp_check script was also created to visualize the grasps generated by the FSM in rviz before integrating it.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/14.jpg" title="Pointcloud - Before Filtration" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/15.jpg" title="Pointcloud - After Filtration" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Point cloud filtration. On the left, shows a pointcloud before filtration and the right shows the pointcloud after filtration.
</div>
<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/16.jpg" title="Grasps - Before Filtration" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/17.jpg" title="Grasps - After Filtration" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Grasp filtration. On the left, shows a grasps before filtration and the right shows the grasps after filtration.
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/18.jpg" title="Grasp pose visualization" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Grasp pose visualization in Rviz.
</div>

<u>Challenges faced and Solutions</u>

 - The perception node works by creating a mask between the image taken before the object is placed in the bin and after the object is placed in the bin. This mask then is taken to collect the points which result in stray points. The graspnet performs poorly when there are stray points in the pointcloud.
    - This was solved by adding an additional pointcloud filtration system which is based on the density of the pointcloud.
    - The density of the pointcloud can also be adjusted as the density of the pointcloud changes with distance from the camera. 

 - The graspnet does not have the capability to <u>detect potential collision</u> with the bin while generating the grasp-pose. 
    - The grasping node will be modified to send in an array of grasps and the path planner can choose the grasp pose which does not have any collisions.

 - The graspnet generates multiple grasp poses and in all directions but it is not possible to attempt all grasps from most directions because of bin constraints. 
    - A grasp filtration system was created which allows only grasps which are within a specific cone.
 - The graspnet requires a particular transformation of the points.
    - The pointcloud is multiplied by a transformation matrix and the pose output is also multiplied by a matrix to get the result in a particular orientation.
